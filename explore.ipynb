{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Insigh Analyst Case Study #\n",
    "\n",
    "We have two similar systems in Xero, full BAS and simpler BAS, for users to fulfill their compliance needs with the ATO. Attached are some extracts of times when each of the reports were being run by our users (simplebas.csv and fullbas.csv), and some metadata about the organisations (orgcard.csv).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit your analysis to active, paying organisations (orgs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, you are looking to present insights to the product manager of BAS at Xero. They would like to see:\n",
    "1. an overview of how and when users interact with each system;\n",
    "2. a comparison in terms of usage of each system;\n",
    "3. a view of seasonality that could inform the need to increase compute capacity;\n",
    "4. your recommendation on what the best time of month would be to have a two hour\n",
    "outage window for each system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some key data points to include in your data story:\n",
    "- What month saw the most report runs?\n",
    "- How many orgs ran both reports?\n",
    "- How many users have used either report?\n",
    "- How many users have run reports for multiple organisations?\n",
    "- Which pricing plans are the most popular amongst organisations using BAS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "Import variable: time stamps, userid, orgid, productopion, payingflag, runtime.\n",
    "\n",
    "### Main Idea:\n",
    "\n",
    "We can build a dashboard that performs time series analyses on FullBAS, and SimpleBAS data. \\\n",
    "First, we can create a plot of general system usage (user/org agnostic) between Full and Simple, 2 overlaying histograms. \\\n",
    "Then, decompose the above to filter for organizations. (we might even be able to do some kind of orgnisation classification here base on usage frequency) \\\n",
    "Hone into FullBAS, weigh the histograms by runtime to identify bottle necks/choking period to determine the need for compute capacity, and spot offtime for best outage window. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement some basic filters:\n",
    "1. time\n",
    "2. paying flags. \n",
    "3. productoption\n",
    "4. orgstatus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "1. Timezone is simple BAS is Australia/Sydney timezone UTC+11\n",
    "2. All users in simple BAS belong to Orgs that are paying Orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime,  timedelta\n",
    "import copy\n",
    "\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgdetails = pd.read_csv('data/orgcard.csv')\n",
    "orgdetails['organisationid'] =orgdetails['organisationid'].str.lower()\n",
    "\n",
    "\n",
    "fullbas = pd.read_csv('data/fullbas.csv')\n",
    "fullbas['datetime'] = fullbas['datestring']+' '+fullbas['timestring']\n",
    "fullbas['datetime'] = fullbas['datetime'].astype('datetime64[s]').dt.tz_localize('Australia/Sydney',ambiguous=True)\n",
    "\n",
    "simplebas = pd.read_csv('data/simplebas.csv')\n",
    "simplebas['datetime'] = simplebas['datetime'].astype('datetime64[s]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpledf=simplebas.groupby([simplebas['datetime'].dt.date]).size().reset_index(name='count')\n",
    "fulldf = fullbas.groupby([fullbas['datetime'].dt.date]).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_time(df, start_date, end_date):\n",
    "\n",
    "    dff = df[\n",
    "        (df[\"datetime\"] > datetime.strptime(start_date, \"%Y-%m-%d\").date())\n",
    "        & (df[\"datetime\"] < datetime.strptime(end_date, \"%Y-%m-%d\").date())\n",
    "    ]\n",
    "    return dff\n",
    "\n",
    "def filter_by_payingflag(df, paying_status):\n",
    "    return df[df['payingflag'].isin(list(map(int, paying_status)))]\n",
    "\n",
    "def filter_by_status(df, status):\n",
    "    return df[df['organisationstatus'].isin(list(map(int, status)))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpledf=simplebas.groupby([simplebas['datetime'].dt.date]).size().reset_index(name='count')\n",
    "fulldf = fullbas.groupby([fullbas['datetime'].dt.date]).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = dict(\n",
    "    autosize=True,\n",
    "    automargin=True,\n",
    "    margin=dict(l=30, r=30, b=20, t=40),\n",
    "    hovermode=\"closest\",\n",
    "    plot_bgcolor=\"#F9F9F9\",\n",
    "    paper_bgcolor=\"#F9F9F9\",\n",
    "    legend=dict(font=dict(size=10), orientation=\"h\"),\n",
    ")\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = html.Div([\n",
    "    dcc.DatePickerRange(\n",
    "                    id=\"date_picker\",\n",
    "                    start_date = '2016-10-01',\n",
    "                    end_date=date.today(),\n",
    "                    display_format='MMM Do, YY',\n",
    "                    start_date_placeholder_text='MMM Do, YY'\n",
    "                ),\n",
    "    dcc.Checklist(\n",
    "                    id=\"payment_status\",\n",
    "                    options={\n",
    "                            '1': 'Paying',\n",
    "                            '0': 'Non-Paying',\n",
    "                    },\n",
    "                    value=['1']\n",
    "                    ),\n",
    "    dcc.Graph(id=\"usage_graph\"),\n",
    "])\n",
    "@app.callback(\n",
    "    Output(\"usage_graph\", \"figure\"), \n",
    "    Input(\"date_picker\", \"start_date\"),\n",
    "    Input(\"date_picker\", \"end_date\"),\n",
    "    Input(\"payment_status\", \"value\"),\n",
    "    )\n",
    "def update_usage_graph(start_date, end_date, payment_status): \n",
    "    \n",
    "    layout_aggregate = copy.deepcopy(layout)\n",
    "\n",
    "\n",
    "    fullbas_w_org = pd.merge(fullbas, orgdetails, left_on='orgid', right_on='organisationid', how=\"inner\")\n",
    "    fullbas_w_org = filter_by_payingflag(fullbas_w_org,payment_status)\n",
    "\n",
    "    simpledf=simplebas.groupby([simplebas['datetime'].dt.date]).size().reset_index(name='count')\n",
    "    fulldf = fullbas_w_org.groupby([fullbas_w_org['datetime'].dt.date]).size().reset_index(name='count')\n",
    "\n",
    "    simpledff = filter_by_time(simpledf, start_date, end_date)\n",
    "    fulldff = filter_by_time(fulldf, start_date, end_date)\n",
    "    \n",
    "    data = [\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                name=\"Full\",\n",
    "                x=fulldff['datetime'],\n",
    "                y=fulldff['count'],\n",
    "                line=dict(shape=\"spline\", smoothing=2, width=1, ),\n",
    "            ),\n",
    "            dict(\n",
    "                type=\"line\",\n",
    "                name=\"Simple\",\n",
    "                x=simpledff['datetime'],\n",
    "                y=simpledff['count'],\n",
    "                line=dict(shape=\"spline\", smoothing=2, width=1),\n",
    "            ),\n",
    "            ]\n",
    "    figure = dict(data=data, layout=layout_aggregate)\n",
    "    return figure\n",
    "app.run_server(mode='inline', port=8050, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isOneToOne(df, col1, col2):\n",
    "    first = df.drop_duplicates([col1, col2]).groupby(col1)[col2].count().max()\n",
    "    second = df.drop_duplicates([col1, col2]).groupby(col2)[col1].count().max()\n",
    "    return first + second == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebb82aa2c10136997439f02c41a80c3bd9bcb94eb211b0088a6341883261a879"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv38xeropia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
